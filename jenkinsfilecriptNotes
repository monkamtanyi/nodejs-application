Jenkins 9 Video Jenkins Shared Libraries and  NodeJS Application

//Code - Build - Test - CodeQualityReport - UploadArtifacts - Deployment - Email Notification
//This pipeline script written in groovy. Now if we have many projects, it means we go thro each stage. 
But we can write common script that can be refereced to build other scripts.


node
{
 
  stage("CheckOutCodeGit") {
   sh "start of project"
  sh "This is a java project for boa"
  git 'https://github.com/LandmarkTechnology/wep-app'   // used to pull the code from github = Code pull
}
 
 stage("Test+Build") {
   // Building with maven
  // sh "mvn validate"
  // sh "mvn compile"
  // sh "mvn test"     note mvn package will execute the 3 commands above which is commented.
     sh "mvn package"  

    }
 
 
  stage('CodeQualityReport') {
   sh " echo running code quality report analysis"
  // sh "sonar:sonar    sonar plugin and sonar goal to execute sonar report"   
   
    }
      
        } 
		
    stage('UploadArtifacts') {
      sh " echo uploading artifacts in nexus"
       sh "mvn deploy"
      }	
 
 stage('Development') {
  sh "echo app now ready for deployment"
// in deploying the application we just copy the application code from the build server (web-app dir) to
//the deployment server (web-server dir)
    sh "scp app.war ec2-user@172.28.19.2:/opt/tomcat9/webapps/"
    }
stage ('Notification'){
sh "mail"     // mail is a command in linux
sh "echo slackchannel"    //to also notify members on slack channels
    
  }
}
Doing the above jenkins pipeline Script is a tedious process, especially as we have many projects. to solve this we use 
Jenkins Shared Libraries JSL:
Jekins Shared Libraries is a concept of having a common pipeline code in the version control system that can be used 
by any number of pipelines just by referencing it. Infact, multiple teams can use the same library for their pipelines.
It is just like calling a function.
programming and scripting languages that we have done in landmark
- bash-shell scripting
-groovy

How do we set up JSL:
-Create shared libraries     jSL has a variable vars dir 
- configure Library
- Use Library in pipeline script

Creating Shared Libraries:
IN the var dir, we have a script called the common groovy, this has steps common to all the stages which can be used for
automation.
//common.groovy   this is the name of the shared library
// under we are calling each fn (eg sh "mvn clean package") based on the string stage name. u can run many commands 
at each stage (eg lile sh " echo running code quality report analysis")
def call(String stageName){
  
  if ("${stageName}" == "Build") {
       sh "mvn clean package"
     }
  else if ("${stageName}" == "SonarQube Report")   {
        sh " echo running code quality report analysis"
       sh "mvn clean sonar:sonar"
     }
  else if ("${stageName}" == "Upload Into Nexus")
     {
       sh "mvn clean deploy"
     }
}

Above is creating a shared libraries, next configure library:
copy the repo were the jenkins library is found
https://github.com/monkamtanyi/JenkinsSharedLibraries
goto jkbrowser,db>managejk>configure system>global pipeline libraries>libraryname= monkamtanyiSS-Sharedlibs  (u can have multiple libraries) >
default version=master-allow defaut version overriden, include@library changes in job recent changes.>
retrieval methoe=modernscm>git>enter jenkins library repo - https://github.com/monkamtanyi/JenkinsSharedLibraries>enter
cred?>save>jenkins shared library is configured.
Next:select a project or lets create one called ebay-bts>pipeline project>ok>conf>ok>pipeline>

Jenkinsfile start jenkinsfile for shared libraries like this  (SS =software solution)
//@Library('LibraryName') _
@Library('monkamtanyiSS-Sharedlibs') _
pipeline{                   //we are going to create a declarative pipeline
agent any
tools{
     maven "maven3.9.6"
  }
stages{
 stage('gitPull') {   //we want to pull d code from our PubGithubRepo
    steps {
        sh "echo start of ebay-bts project"
          git 'https://github.com/monkamtanyi/maven-web-application_public'
        //git pull is not part of my shared library, if u check the library file there is no stage as git pull, so pull the repo from git)
       //CTrl+C copy pipelinscript Ctrl+V =paste in jkPipeline>
     }
  }
      stage('Build') {  
    steps{
        common("Build")    // u can decide to change the name common.groovy to cdc.groovy, but remember to use cdc in 
   }                             d place of common. this applies to stages and Build.
  }
  stage('Execute SonarQube Report') {
    steps{   
         sh " echo running code quality report analysis"
      // common("SonarQube Report")
    }
 }
  stage('Upload Artifacts Into Nexus') {
     steps {
         sh " echo uploading artifacts"
         //common("Upload Into Nexus")
       }
    }
 }
}
if you go to the jenkinsSharedlibrary folder you will see 
common.groovy
build.groovy
stage.groovy.
if u call d fn from common then d step will be common, if i cll the fn from build, the step will be build, follows
same for stage.

lets call the fn from build
@Library('monkamtanyiSS-Sharedlibs') _
pipeline{                   //we are going to create a declarative pipeline
agent any
tools{
     maven "maven3.9.6"
  }
stages{
 stage('gitPull') {   //we want to pull d code from our PubGithubRepo
    steps {
        sh "echo start of ebay-bts project"
          git 'https://github.com/monkamtanyi/maven-web-application_public'
        //git pull is not part of my shared library, if u check the library file there is no stage as git pull, so pull the repo from git)
       //CTrl+C copy pipelinscript Ctrl+V =paste in jkPipeline>
     }
  }
      stage('Clean') {  
    steps{
        build("Clean")
   }
  }
  stage('Compile') {
    steps{   
         sh " echo running compile"
      // build("Compile")
    }
 }
  stage('Test') {
     steps {
         sh " echo uploading artifacts"
         //build("Test")
       }
    }
     stage('Package') {
     steps {
         sh " echo uploading artifacts"
         //build("Package")
       }
   }
  }
}

we can also call d fn from stages:

@Library('monkamtanyiSS-Sharedlibs') _
pipeline{                   //we are going to create a declarative pipeline
agent any
tools{
     maven "maven3.9.6"
  }
stages{
 stage('gitPull') {   //we want to pull d code from our PubGithubRepo
    steps {
        sh "echo start of ebay-bts project"
          git 'https://github.com/monkamtanyi/maven-web-application_public'
        //git pull is not part of my shared library, if u check the library file there is no stage as git pull, so pull the repo from git)
       //CTrl+C copy pipelinscript Ctrl+V =paste in jkPipeline>
     }
  }
      stage('Build') {  
    steps{
        stages("Build")
   }
  }
  stage('SonarQube Report') {
    steps{   
         sh " echo running code quality report analysis"
      // stages("SonarQube Report")
    }
 }
  stage('Upload Into Nexus') {
     steps {
         sh " echo uploading artifacts"
         //stages("Upload Into Nexus")
       }
    }
 }
}

we have seen java appliications which we call java projects now lets go to 
nodejs applications which we call nodeJS Projects:

nodejs appication -------> nodeJS Projects

nodejs-APP                VS                   Java-APP               in landmark we use maven to build in java-app and in
npm                       =                     maven or gradle  --->  Build   nodejs-app we use npm(node package manager)
package.json                                    pom.xml                 Build Script BS when doing a build u need a BS
npm install                                     mvn package             creating packages
npm test                                        mvn test                 run unit test cases
npm run sonar                                   mvn sonar:sonar           SonarQube CodeQualityReport
npm publish                                     mvn deploy                uploading artifacts

The BS is pom.xml using maven and package.json using the node package manager.
Nest we do a pipeling project using nodejs application.

src + BS + test cases
sudo yum install nodejs npm -y  = //[jenskins@cd ~]$sudo yum install nodejs npm -y

db>newItem>name=ebaynodejs-app>pipeline>save>pipeline script>

node {
stage('CodeCheckout'){
 sh "echo running ebay nodeJS projet"   lets get a Purepo and use git to clone it from github, u don't need credentials as
git 'https://github.com/LandmarkTechnology/nodejs-application'     as it is a PrivateRepo and it runs in d master branch
     // git 'https://github.com/monkamtnayi/nodejs-application'          forked repo
  }
    Stage (UnitTest') {                              //u may want to run unit test cases b4 build
        sh "echo unit test cases successful" 
        //sh "npm test"                              canot run bcos no test cases is specified - there is no test cases
}

   Stage ('Build') { 
    sh "echo creating build artifacts"   // we are doing scripted pipeline Build. install nodejs in jk b4 do bill
   nodejs(nodeJSInstallationJame: 'nodejs17')
     sh "npm install"                             // now copy the script to the pipeline script job>buildNow
  }                                           //to get latest version of npm>goto db>manage jk>gobal tool conf>nodejs>
                                            {if y don't see nodejs goto plugin and install nodejs)> nodejs installation>
stage('Quality Report') {                     u will see the current version>(goto jenkins server and version check
   sh "echo CodeQualityReport"              $npm -verdion) goback to jk browser >add NodsJS>nodejs17 -the version u see>
nodejs(nodeJSInstallationJame: 'nodejs17')  save, u can now use this latest nodejs version in ur jk jobs - call the latest
 sh 'npm run sonar'                          verion as shown left side (nodejs(nodeJSInstallationJame: 'nodejs17')).
  }                                            Next step sonarqubereport>nodejs-application repo>sonar-project.js>edit>goto 
                                           sonar server browser and copy url or use ipaddress and insert(just belowsonqube-
stage('UploadArtifacts') {                     scanner} (sonar-project.js =pom.xml). next create a token (u can as well
sh "echo npm packages Uploaded"               use sonar.login= admin and passwd admin- better to create a token>goto sonar
 nodejs(nodeJSInstallationJame: 'nodejs17')    browser>administration>security>uses>under or in admin>token>name-nodejs>
//  sh 'npm publish'                              generate>copy token>goto sonar-project.js and replace d token>commit changes.
//jenkins nexus integration *                                                copy to pipbeline script>apply>save>buildNow>got sonaqube server in browser
//passwd = Admin123, username=admin         and check for the report' what is ur job- I have been maintaining, updation
 //echo -n 'admin:admin123' | openssl base64
  }                                                 modify and customize jenkinspipeline jobes and jenkins shared libraries.
                                                 when u create a nodejs application it generates npm packages.
  stage('deployment')  {                                              * goto nexus server in browser>create repo>npm(hosted)>name=ebay-npm-repo>
    sh "echo deploying application"                                                deployment policy=allow redeploy>create>copy repoUrl>goto project>    nodejs(nodeJSInstallationJame: 'nodejs17')                                          package.json =pom.xml>insertUrl in registry under nodejsexample>commit>
   nodejs(nodeJSInstallationJame: 'nodejs17')                                            u can change passwd>account>iD=admin>firstName=Administrator>LastName=User>
    sh 'npm start'                                              Email>changePasswd>admin>admin123>now chaneTo>Admin@123
                                                We can create a token for passwd and username>use a command in base64
  }                                               software. goto nodejs-application repo>views>Readme.md>
 }                                        run this command to encript the username and passed:
                                         //echo -n 'admin:passwd' | openssl base64  as in leftside. run d command as
                                        [jenkins@cd ~]$echo -n 'admin:admin123' | openssl base64 . copy d token> goto 
                                         .npmrc file (inRepo)>enter token line3 after _auth=enter token here>it looks 
                                          like this _auth=echo -n 'admin:admin123' | openss1 base64. next copy this stage
                                        to jk project>pipeline script>save>buildNow. Prof commented line did't wk. I'll
                                         try to run it (sh 'npm publish').
                                         Next deploy>copy as shown to project script>buildnow. we are deploying to 
deployment server not tomcat. prof will revisit this project in docker. open console output, goto bottom u will see 
"Node JS app is running at 1) http://localhost:9981/landmarktechnologies" u cna acess d app using this url
get jenkins url: https//18.212.54.48:5555/job/ebay-nodejs-app/14/console.
Replace localhost with jenkins Ipaddress in 1) and access it on a browsr.
this application has a port no. and some RESTFUL API =application programming interphase.
this is one of them =http://localhost:9981/landmarktechnologies, u can use rest api to access info.
goto nodejs-application to see how many api are there>app.js>u see a get request- app.get ("/html... /jsonData... etc).
so u can access the rest application called jsonData like this : https//18.212.54.48:9981/jsonData
also html rest api :https//18.212.54.48:9981/html
also redirect rest api :https//18.212.54.48:9981/redirect ; will redirect traffic to mylandmarktech.com - see it under
app.get(redirct ...)
also https//18.212.54.48:9981/queryparam - prof ran it, showed undefined
try the redirect - took us to landmark technology website
restful jsonData - it takes us to some landmark info - email, contact, name etc.
if we were deploying this appli as a docker container d port no is 9981' Dvpers have exposed this appl on thisport.
so when we want to access this appl it has a context path and a port no. and all this these are what we call REST APIs'
this is how we are able to deploy a nodejs appl.
as devops engr. ur fn is to ensure that this appli is 
- high availability - these rest apis shld be accessible.
so we are going to create New-Relic to create monitoring dasboard (see video). eg google new-relic monitoring dashboards.
we will use these monitoring dbs, bcos in real time we will not be clicking each rest api to see if its avaiable-
one appl can have like 50 rest apis, meaning u can access more than 50 resorces - to make sure they are availble use
monitoring tools to momitor ur appl to make sure they are highly available.
Check these videos: new-relic 55min, resume preparation 55min. we are 50% course ach.

END OF JENKINS
jenkins master slave arcitecture: in real time we want to maximise the uptime of our savers- ie the length of time it has ran
contiuuouly without failing. mabe it has ran for 2yrs without failing that's uptime. to avoid jk servers from failing, we 
can configure jobs to run on slave servers. if u are running a jk job on a slave, whatever runs on that slave, the job
is backed up there automatically. if the master goes down and u were creating artifacts on those slaves, u can go back
and see the jobs that you had created on those specific slave servers. Note that we are creating a jk master slave 
architecture in d sense that if the jk master fails we won't have any provlem, secondly he helps us achieve speed in a
situation were multiple jobs is run- we cna run them concurently, ie we can have multiple executors and jk executors are
those parameters in jks which enable jk to run jobs in jk slave servers. in a complex pipelin project were u may have to use 
multiple agents - say u have a pipeline were u decide to configure say sonaqube as an agent, 
How can u backup >plugin manager>availble>search backup>we have options like:
periodic backup: backup or restore ur jk configuration files at stipulated times
backup and interrupt job plugin: prepare jk for restart
google cloud backup: allows local and cloud-storage bkups and automatic restores
Thinbackup: bkups d most important global aand job sepecific configuration files. open thinbackup:
gives 3 options: bkup now, restore, bkup settings (create bkup in jk home dir, bkup schedule for full bkups,max. no. of bkup sets
prof had 5>force jk to quite mode after specific minutes prof =12>, bkup build results prof ticked bkup build result,
bkup user content folder, bkup next build number file, bkup plugin arcchives click save and click bkup now- everything 
about ur jk jobs is going to be backup.  eg [jenkens@cd ~]$ls jenkinsbackup -prof result FULL -2021-12-16_16_40
etc)
[jenkens@cd ~]$ls jenkinsbackup/FULL -2021-12-16_16_40 : u get everythings about ur jk servers :jobs, plugins,users etc has 
been backedup. we can decide to have one max. backup, and the rest backup as zip file(tick move to zip) in landmark we 
use the thinbackup to bkup our jobs, plugins and other jk files - if a new recruit by deletes files just go to restore.

Dvpers write restfulapis as part of the appl.js, helps u to get info on specific content.

APPLICATION PERFORMANCpE MONITORING APM WITH NEW RELIC
U query a relic to get info. 
Interview answer: I have been able to configure, monitore db relic with over 50 restful APIs ex. API 
http:/54.82.188.178:7777/myapps/services/employee/getEmployeeDetails
New Relic nr is one of d tools that is being used by most companies to ensure that their appl is performing as expected.

NR benefits
high availability
avoid reactive panics
performing as expected
achieve zero downtime

NR =SaaS good for my cv
nr is a continuous monitoring tool.
IT is a software as a service appl. I don't need a server to run nr, it is a fully managed service. remember we need a 
server to install jk or tomcat or maven etc.
create an account on nr.
monkamtanyi@yahoo.co.uk
goto infrastructure: u can use new relc to monitor infrastructure hosted on aws, kubernetes, windows, linux server etc.
it can also monitor logs but it is not open source - need to pay. will not use this. will use other tools.
https://one.newrelic.com/synthetics/monitor-create?account=4407585&state=704d97cf-2c9d-0eb8-bca3-d682a8c823a8
goto ping- use to show weatherthis appl is up and runing at all time. it is going to check d rest api eg get employee info.
>Name=EmployeeDetails>enter url (rest api) it is going to ensure that employee details stored on this url 
is highly available.>can add a validator can be one employee-copy name from json file>  advance options: include
verify ssl: this ensure only people with secure connection can access this restful api prof choosed Bypass Head request,
third option redirect failure.>period -how often u want this info - prof cloose every 1min.>select monitoring locations - where are customers located. select location - aim is to find 
out how long it takes for clients in this location to access this appl. so that corrective measures can be taken
to make sure latency is reduced to minimum>create monitor>u will see a db showing latency time for each region.
If it's taking more time for clients in cape town africa to access this appl, how can we correct?
when end users from wherever want to access this appl. we are going to route their traffic with a elastic load 
balancerELB (coulbe a web server - apache, tomcat whatever server). this load server is going to distribute this 
traffic based on where u are going to connect from( if u are connection from usa, ur traffic may be routed to say
our ec2 (tomcat servers - in this class we shall see how to install this serverless) . north verginia, these tomcat
servers are running in ec2 instances (linux servers). if a customer is accessing d restful api from africa, d 
router ELB will transfer your traffic to tocat server running in captown region.
this is in a bid to achieve low letancy. 
luckily aws these servers in serveral regions of the globe.

if the response or text validation (the expected string) is not found (the validation name u put - the restful api 
will check for it and if it does not find it, it will return this response- so you need to opwn the rest api to 
check if that name is there)
or if the server is not working - u get a message server timeout meaning the restful api cannot be accessed.- 
maybe u need to retart d tomcat server ([ec2-user@ip-172-31-42-213]$sudo -i, then [root@ip-172-31-42-213]#startTomcat -
generally this ping db helps visualize customer issues to enable u fix them.

Anser: I have been able to create monitoring db using nr, for restful APIs.
So now we have created one db monitor for synthetics EmployeesDetails. so we can can create several db monitors eg get 
customerDetails etc,

we also have the api test, this is used for secure restful APIs, apis that u will need to validate wiht username
and passwd  that's what we call secure restful apis.
so if some one wants to enrol into landmark then i need to share we him this restful api to enable him click and enrol.
and if u have to sign in with passwd and username that becomes a secure restful api, se shall do what is called an 
api test.
Scripted browser- semi script will be written to achieve this task.
Simple browser: u can create a monitor for d entire appl.


 Load balancing with Nginx - Tomcat - 3-Tier app deployment 

loading a virtual machine takes minutes but creating a container takes seconds. using container in a company is a 
big deal.

[ec2-user@ip.23.45.33.23 ~]$sudo hostname nginx
[ec2-user@ip.23.45.33.23 ~]$sudo su -                bcome root user
[root@nginx ~]#
[root@nginx ~]# yum install nginx -y                 install nginx
 [root@nginx ~]#systemctl enable nginx
 [root@nginx ~]#systemctl start nginx
 [root@nginx ~]#systemctl status nginx
http://54.224.111.243:80  access on browser
[root@nginx ~]# cat /etc/nginx/nginx.conf           config file.

server {
        listen       80;
        listen       [::]:80;
        server_name  _;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

 server {
#        listen       443 ssl http2;
#        listen       [::]:443 ssl http2;
#        server_name  _;
#        root         /usr/share/nginx/html;

create a backup for this nginx-webserver
sudo mv  /etc/nginx/nginx.conf /etc/nginx.conf.bkup
vi /etc/nginx/nginx.conf   we want to recreat this 

Load Balancer: benefit
load balancing
Performance
security
patching and upgrading
Health Check : it will not send traffic to a server that is not healthy (eg there could be a spike of traffic, meaning that 
server can not receive traffic, or maybe java process in tomcat server may not be working well making the server
unhealthy)

LB recieve traffic from users take it to our app and then to database
users ---> LB ---> App --->DB : u see LB acts as a layer of security, whereby if someone wants to hack into 
our system, he can be stopped at this stage.

when u type www.app.com or google.com or landmark.om what happens:
in the back end u querry  global DNS (domain name service)
there is a command in the backend called nslookup (name service lookup), it searches d server (ie nslookup
points the address (nginx webserver ip) of www.landmarkmu.org).  LandmarkTechnologies@simonLegah
MINGWA64 ~/Music/NGINX/maven-web-application (master)  

$nslookup www.landmarkmu.org
so if u run nslookup www.landmarkmu.org it will tell u that this 
puIp is pointing to the nginx webserver and traffic will be routed to that server.

try $nslookup google.com : it will show u the webserver that google.com is running on or associated with.
$nslookup facebook.com: gives u the webserver fb is running on.

















